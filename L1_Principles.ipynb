{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "L1_Principles.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "X5h41XeBBWcK",
        "AHZRZ45sMUBw"
      ],
      "toc_visible": true,
      "mount_file_id": "11MBPducEj0HgT0u-nrCE60AvHJQnPR3y",
      "authorship_tag": "ABX9TyOHOcWMFUVQkBZCrTfkz5Q1"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5rHzwUorF5ab"
      },
      "source": [
        "<img src=\"https://github.com/christopherhuntley/DATA6510/blob/master/img/Dolan.png?raw=true\" width=\"180px\" align=\"right\">\n",
        "\n",
        "# **DATA 6510**\n",
        "# **Lesson 1: Principles & Overview** \n",
        "_The whole course from 40,000 feet_\n",
        "\n",
        "## **Learning Objectives**\n",
        "### **Theory / Be able to explain ...**\n",
        "- Importance of data for decision making\n",
        "- Features and components of database systems \n",
        "- Data models and data integrity\n",
        "- Functions of a DB Management System\n",
        "- Terminology like apps, layers, DBMS, SQL, metadata, etc.\n",
        "\n",
        "\n",
        "### **Skills / Know how to ...**\n",
        "- Identify the parts of a database table\n",
        "- Use keys to match records from separate tables\n",
        "- Run SQLite queries in a Jupyter notebook\n",
        "\n",
        "\n",
        "--------\n",
        "## **LESSON 1 HIGHLIGHTS**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I95WVwkCnTJF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 579
        },
        "cellView": "form",
        "outputId": "816d98a5-983b-4f8c-9e2e-fb0621c2afd3"
      },
      "source": [
        "#@title Run this cell if video does not appear\n",
        "%%html\n",
        "<div style=\"max-width:1000px\">\n",
        "  <div style=\"position: relative;padding-bottom: 56.25%;height: 0;\">\n",
        "    <iframe style=\"position: absolute;top: 0;left: 0;width: 100%;height: 100%;\" rel=\"0\" modestbranding=\"1\"  src=\"https://www.youtube.com/embed/-a9C4VWjr7Q\" frameborder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>\n",
        "  </div>\n",
        "</div>"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div style=\"max-width:1000px\">\n",
              "  <div style=\"position: relative;padding-bottom: 56.25%;height: 0;\">\n",
              "    <iframe style=\"position: absolute;top: 0;left: 0;width: 100%;height: 100%;\" rel=\"0\" modestbranding=\"1\"  src=\"https://www.youtube.com/embed/-a9C4VWjr7Q\" frameborder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>\n",
              "  </div>\n",
              "</div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X5h41XeBBWcK"
      },
      "source": [
        "## **BIG PICTURE: Where does data come from? Why do we care?** \n",
        "\n",
        "Data lives in a somewhat unique place in between technology and people. **Without people there is no data.** Data is a strictly artificial (i.e., human generated) artifact, our record of facts observed and imagined. It is also artificial in another sense, in that **it can't exist without technology.** Facts that remain locked in our heads are not data. They are just thoughts and memories that have to be **encoded into data** so they can be communicated, stored, updated, and (eventually) purged altogether when we don't need them anymore. Technology is how we do all that. Without it we are lost. \n",
        "\n",
        "In a real sense, understanding how data works and where it comes from gives us a peek inside how people think and, more specifically, how people make good decisions. Every ***rational*** decision involves at least four stages:\n",
        "- A **stimulus** that prompts the need for action\n",
        "- Collection of ***potentially* relevant facts** about alternative courses of action\n",
        "- Development and application of **decision rationale** (models) informed by the facts and objectives\n",
        "- Selection and **execution of a course of action** in keeping with the rationale  \n",
        "\n",
        "Or, to put it another way, when trying to hit a target when it really counts, the best plan of action is more like Ready $\\rightarrow$ Aim $\\rightarrow$ Fire with information and intention instead of flailing about randomly in the dark with hunches based on nothing, explainable to no one.\n",
        "\n",
        "Good leaders *who have to be accountable to others* can explain *why* they make decisions, *what* supporting evidence was used, and *how* they can be persuaded to act differently. Otherwise, why would anyone in their right minds choose to follow them? A common thread here is access to relevant data, which allows them to formulate, validate, communicate, and act on their decisions. \n",
        "\n",
        "So, if you really want to succeed in business, it is best to treat data as a critical resource, worthy of continual investment of time, money, and attention. Can you access data when you need it? Can you trust what it is telling you? Is it relevant to what you need to know at the time? Can you integrate data from multiple sources? Can you then communicate decisions in a way that any rational person can agree (or disagree) with? If not, then expect lots of unfortunate surprises and in some cases outright failures. \n",
        "\n",
        "And where does that data reside? Hopefully, in a **database system** that has been designed to meet the specific needs of the people using it. In this lesson we will sample ideas from the lessons that follow, providing just enough information to explain where we are going and why we need to go there.   \n",
        "\n",
        "> ### TLDR for the impatient\n",
        "> * Access to data and information are fundamental to modern business\n",
        "> * Management is about decision making\n",
        "> * Good decisions require information and rationale\n",
        "> * Good information requires relevant, accurate, and timely data  \n",
        "> * Ideally, that data is managed in a database system that has been designed for the needs of those who use it\n",
        ">\n",
        "> $\\Rightarrow$ Important to understand how databases work and interact with business applications, getting as close to original source data (i.e., the unadulterated truth) as you can manage\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AHZRZ45sMUBw"
      },
      "source": [
        "## **Database Systems: Three Different Perspectives**\n",
        "Any system that relies on the use of a data store is considered a database system. With that very broad definition, just about any \"smart\" device or app you use today is a database system. A smart watch that collects and stores data about the wearer is a database system, as is an email client that retrieves and archives email for reading later or the point of sale system used at the bodega around the corner. \n",
        "\n",
        "In this lesson we will look at database systems three different ways:\n",
        "- **Technical Architecture** describes hardware and software resources that need to be bought, installed, integrated, maintained, and secured.   \n",
        "- **Software Architecture** describes the logical structure of the system and how data is processed. \n",
        "- **Data Architecture** describes how the data itself is organized, used, maintained. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BtUFh7tdEYdh"
      },
      "source": [
        "---\n",
        "## **Technical Architecture: Networks, Devices, Apps, and Servers**\n",
        "\n",
        "![Enterprise Architecture](https://github.com/christopherhuntley/DATA6510/raw/master/img/L1_enterprise_architecture.png)\n",
        "\n",
        "When viewed with an IT director's eye, technical resources include anything that has to be installed. Consider, for example, the technology needs of a small regional retail chain, as diagrammed above. \n",
        "\n",
        "At each **retail location** (on the left), one would find a number of devices needed to complete sales, track inventory, and report to headquarters. While some of the technology might be proprietary, much of it would be licensed from vendors who specialize in retail systems. \n",
        "\n",
        "At the right is the **corporate headquarters**, where functional managers and executive staff make decisions about marketing, human resources, supply chains, technology, etc. The needs of these executive offices are somewhat less industrial than the retail locations, with more of a need for historical data that can be analyzed offline. While they may, in fact, need to monitor individual transactions (e.g., if fraud is detected) they usually work with aggregated data (data marts) constructed to support specific kinds of decisions.\n",
        "\n",
        "Somewhere in between the stores and headquarters is a **centralized data center**. Invisible to the users, this is where all the work is done to process and record the transactions (sales, incoming orders, outgoing shipments, etc.) that are the beating heart of the enterprise. It cannot be exaggerated how critical these central servers are: if they go down or are hacked then *everything* else reverts back to pencil and paper. \n",
        "\n",
        "Connecting the various locations together is a **virtual private network (VPN)** that is secured using state of the art technology. Like the central servers, these networks are potentially always under attack. If a remote hacker is going to gain access to the systems then it is going to be over the VPN. (However, despite what you see in the movies, virtually all black hat hacking actually happens *within* the VPN rather than through some cryptographic hack of the network itself. Usually, a user exposes a password, installs a bit of malware, or is the criminal in question.)\n",
        "\n",
        "### **Scale: Embedded / User / Workgroup / Enterprise**\n",
        "\n",
        "Database systems come in different sizes, each with different needs and operating characteristics.\n",
        "\n",
        "Some are so small that you barely know they are there, **embedded** in other hardware and software. So, for example, the scanning wand used by a point of sale system may keep a cache of recent scans. Or your sports watch keeps a record of your heart rate that is synced (uploaded and reset) through an app on your phone. Often, if the device is turned off (all the way off, not in hibernation) for a long enough period of time, the data is lost. However, with static memory and solid state disks becoming cheaper and smaller every day, even the smallest devices often come equipped with persistent storage that survives a reboot. \n",
        "\n",
        "The next level up is data stored in files by an **end user app**. Such data will usually survive a system restart, though perhaps with some corruption if the system was writing data to storage at the time. In our example, the point of sale system may have a local storage mechanism so it can recover from power outages, void incorrect transactions, etc. Similarly, behind the scenes most desktop software stores data in caches, documents, or other kinds of files in order to improve the overall user experience.  \n",
        "\n",
        "At a broader level are so-called **workgroup applications**, where data access is shared with a limited number of other users and devices on the same local area network (LAN). In our retail example, the back office systems and inventory systems might share a workgroup server that keeps track of recent activity. At the other end of the diagram, a similar setup connects the executive information systems and the analyst workstations to the data marts and file archives needed to do their work. \n",
        "\n",
        "At the largest scale are the **enterprise** systems in the center of the diagram. They are not necessarily designed for raw speed but instead for throughput. The data on these servers may come from hundreds or even thousands of devices or users, and it is more important that each transaction complete correctly than that any particular transaction complete quickly. \n",
        "\n",
        "### **Usage: Transaction Processing vs Analytical Processing**\n",
        "\n",
        "In our retail example, there was a contrast between the operational systems used in the retail locations on the left and the decision support systems used by the headquarters on the right. \n",
        "\n",
        "We call the kinds of work performed by the retail locations and the central data center **transaction processing**. The emphasis is on capturing *what is happening right now* in as much detail as needed and then storing it for posterity. The transaction server and database are thus designed for writing data quickly and accurately, without dropping any transactions due to bandwidth constraints or technical failures. \n",
        "\n",
        "The work performed at headquarters, meanwhile, tends to be what we call **analytical processing**. Here the emphasis is on aggregating and understanding the transactions data and perhaps integrating it with other data collected elsewhere. These sorts of activities are more about data integration and communication, with read-only access to (scrubbed and aggregated) historical data in a data warehouse or data mart. Such systems may be nearly as large as the transaction systems, in that they contain the same basic volume of facts, but they do not have to support as many users and are less subject to data corruption. Read-only data is not corruptible. If it is corrupt then it was so when it was created. \n",
        "\n",
        "### **Security: Files / DBMS / Services**\n",
        "\n",
        "We conclude our discussion of information technology with a note about the effect of architecture on privacy and security. As an illustration please consider the three \"houses\" below, each of which are designed with security and privacy in mind. The first is Philip Johnson's world famous Glass House, which looks stunning but would not provide much in the way of privacy. In the center is Johnson's almost as famous brick Guest House, a windowless structure with a single door that would provide lots of privacy and security, except for the easily accessed skylights on the roof. Lastly, we have the bomb shelter on the right, which provides maximum security and privacy but only if one is willing to trade off natural light and air.   \n",
        "\n",
        "![Glass Brick Concrete](https://github.com/christopherhuntley/DATA6510/raw/master/img/L1_glass_brick_concrete.jpg)\n",
        "\n",
        "**The Glass House is analogous to files on a local hard drive or in an email attachment.** Just as the thick panes of glass give the appearance of security but not any privacy, so does relying on file storage to keep your data safe. The contents of your files are visible to anyone with physical access to the storage device or network. While we can, of course, provide security ourselves $-$ with curtains for the house or encryption for the files $-$ doing so would potentially spoil the elegance and convenience of the original design. *So, unless you want to spend your time worrying about private data leaking out of your organization on thumb drives, email, etc. then do not rely on file storage to secure your files. It's about as insecure as it gets.*\n",
        "\n",
        "**The brick Guest House is like direct access to a Database Management System (DBMS) over a secured local network.** By providing a single point of access (i.e., a thick wooden door), such systems make it fairly simple to secure the data behind a user authentication and authorization system. *However, just as the brick house's skylights can potentially be compromised, so can a database located on a local network drive. Its files may take longer to break into but with time can be compromised by those with the patience and skill to do so.*\n",
        "\n",
        "**Finally, the bomb shelter is equivalent to an encrypted database that can only be accessed through a secure application server.** In this case, *all access* is limited to the specific commands (service requests) implemented by the app server. While in principle we could argue that a DBMS is itself an application server, in this case we have the ability to layer on more security beyond what is provided by the database vendor. It is certainly inconvenient, but is about as secure as it can possibly be. \n",
        "\n",
        "**So, whether you are storing data in the cloud or or your local hard disk, be sure that you use a secured network, with a single point of access to the data. Even then, use encrypted file storage to provide one more layer of protection from those with physical access to the server. What you may lose in raw speed will be more than made up for with peace of mind.** \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5V7nDoM1D1g-"
      },
      "source": [
        "---\n",
        "## **Software Architecture: Presentation / Logic / Data**\n",
        "\n",
        "![Three Tiered Architecture](https://github.com/christopherhuntley/DATA6510/raw/master/img/L1_three_tiered_architecture.png)\n",
        "\n",
        "**If we ignore networks and devices, then all remaining technology is software.** Conceptually, if technology is an organization's brain and central nervous system then software is its mind. The wiring, neurons, synapses and other parts exist to implement the thinking and executive processes needed to survive. Similarly, **information technology exists to implement the software** that makes it useful. \n",
        "\n",
        "Virtually all modern software implements some variation of the three part structure shown above:\n",
        "- The **presentation** tier (or layer) that the end user sees and interacts with. To many users this is the totality of the software. Perhaps the most familiar example is the web browser, which many Microsoft users of a certain age still call \"the Internet\" even though Internet Explorer has been officially dead for many years now. \n",
        "- The **logic** tier that connects the user to other users, retains information that may be useful later, controls access to critical resources, etc. In its simplest form, it is defined by a set of actions or **requests** to be carried out by an application service. Continuing with our web example, each web page is assembled by the web browser through one or more requests made of the web server. Each request is received, authorized, and (potentially) executed, with a **response** (HTML, CSS, javascript, file, etc.) delivered back to the browser for presentation to the user.  \n",
        "- The **data** tier that is responsible for reading and writing persistent data. If the entire system is rebooted from scratch, then all essential data should be restored from storage by the data tier. If any data cannot be restored then the data tier should initiate a **rollback** of any data that has become invald because of the loss. \n",
        "\n",
        "In our look at software we will take an operational view of database systems:\n",
        "- How the three tiers cooperate (via requests and responses) to carry out a business transaction \n",
        "- The operations, functions, and features of database management systems (DBMS)\n",
        "- SQL Standards for relational database systems\n",
        "- How we will use SQL in this class \n",
        "\n",
        "### **The Transaction Lifecycle**\n",
        "\n",
        "Consider this everyday sales transaction at a mom-and-pop retailer near you:\n",
        "1. The customer selects a few items off the shelves and then approaches the cashier to check out. \n",
        "2. The cashier asks for the customer's phone number or other identifying account information to \"make future checkouts easier.\"   \n",
        "    2a. If the customer refuses (\"the number is unlisted\") then the cashier enters a dummy customer number (like \"000000\") and continues on with the transaction.    \n",
        "    2b. If the customer supplies a phone number, then the cashier looks up the customer in the system. If the customer does not exist in the system then the cashier asks for a name and creates a new customer account.  \n",
        "3. The cashier rings up the items and calculates a total. \n",
        "4. The customer pays with cash or credit card. \n",
        "5. The system confirms the transaction as valid and complete. \n",
        "6. The cashier offers a receipt and tells the customer to have a good day. \n",
        "\n",
        "It seems pretty simple, right? Now let's look at the same transaction as a set of requests and responses between the Point of Sale terminal, the Transaction Server, and the Database Server. To keep things simple, let's assume that the customer does not have an account but is willing to set one up. Each arrow on this UML sequence diagram is a request (solid line) or a response (dashed line) from one system to another. The logical order is always top to bottom, with interactions at the top occurring before the ones below them. \n",
        "\n",
        "![Sales Transaction](https://github.com/christopherhuntley/DATA6510/raw/master/img/L1_sales_transaction.png)\n",
        "\n",
        "Note that most server responses come only after issuing requests for help from the database. The requests are in SQL, of course, with responses that may include data or just a response code (e.g., \"OK\"). \n",
        "\n",
        "So ... it's not so simple after all! Here all of the requests succeed (with data or an \"OK\" response) but the system needs to also handle failed requests. We also didn't consider the possible transactions with the credit card company. Depending on the system design, those may be processed by the POS terminal or the Transaction Server. \n",
        "\n",
        "And if the system suffers a catastrophic failure, where does it look to start a reboot? With whatever data is in the database. In most cases, that's just fine. However, if the database itself shuts down in the middle of recording a transaction then it needs to *rollback* its data to just before the failure and notify the server of the error, which then gets reported to the sales terminal. We'll consider such cases in Lesson 8. \n",
        "\n",
        "### **DBMS Operations, Functions, and Features** \n",
        "\n",
        "As we saw with the sales transaction, even everyday business gets pretty complicated when we have to implement it in software. From the perspective of the database, however, there are only four kinds of **operations**: \n",
        "- **Create** (add) new data. Upon storage, the DBMS should respond with an identifier for retrieving the data later. \n",
        "- **Retrieve** specified data. The request is often called a *query* and the response includes a data *payload* and perhaps some descriptive *metadata*. It is possible, depending on the query language, to return collections of data if needed. \n",
        "- **Update** specified data. The request indicates what data is to be updated and how it is to be modified. The response indicates whether the update was successful. \n",
        "- **Delete** specified data. The DBMS either deletes the data or returns an error code if the data cannot be deleted.   \n",
        "\n",
        "These fundamental operations are commonly referred to by the acronym CRUD and are found in every database system regardless of the technology or use case. \n",
        "\n",
        "As DBMS technology has matured, the industry has agreed on a few standard functional definitions (shown below). We will consider many of these in more detail in Lessons 7 and 8. \n",
        "\n",
        "Within and beyond these standards, there is plenty of room for DBMS vendors to innovate. We will consider vendor-specific features (also shown below) in our discussion of NoSQL and Distributed DBMS technology in Lessons 11 and 12. \n",
        "  \n",
        "![DBMS Functions and Features](https://github.com/christopherhuntley/DATA6510/raw/master/img/L1_dbms_features_functions.png)\n",
        "\n",
        "### **SQL Database Standards**\n",
        "\n",
        "**The *lingua franca* of DBMS technology is Structured Query Language.** It is the standard against which *every other* database technology is defined. Further, while there are dialectical differences between the various SQL implementations, they are relatively rare, allowing most SQL queries to run unmodified between DBMS vendors. There may be quicker or easier vendor-specific ways to code a particular query, but there will also be a *standard* way. \n",
        "\n",
        "**SQL is more than just a language.** Each DBMS vendor provides a *platform* with tools, apps, and other utility software. To keep the chaos at a minimum, SQL Standards include specifications for DBMS functionality like ...\n",
        "- How to connect to a database and initiate a request\n",
        "- How data is stored and organized\n",
        "- How transactions are handled to prevent data corruption\n",
        "- How user permissions are granted and revoked\n",
        "\n",
        "We will run a few simple SQL queries in the next section and then again for pretty much every lesson in this course. \n",
        "\n",
        "### **Jupyter, Colab, and %sql Magic**\n",
        "\n",
        "In this course we will interact with a variety of different database servers, but we are generally only going to use one database client: `ipython-sql` running right here inside our Jupyter notebooks. \n",
        "\n",
        "We first learned about Jupyter in Lesson 0. It is a programming and reporting environment that combines formatted text and runnable code organized as \"notebook\" documents. There are different flavors of Jupyter notebooks from various vendors. What follows assumes that you are using Google Colab, though most actions translate pretty well to the other Jupyter variants. \n",
        "\n",
        "Text is entered in Markdown format into text cells. If you double click on this text you can see Markdown formatting for yourself in a fairly large text cell (screenshot below). When open this way, the cell is editable. If you modify anything then the formatted text (displayed to the right) also changes. Double-click the formatted text to hide the markdown text. \n",
        "\n",
        "![Markdown Screenshot](https://github.com/christopherhuntley/DATA6510/raw/master/img/L1_markdown_screenshot.png)\n",
        "\n",
        "Runnable code is entered into code cells, identified by icons to the left of the cell. Pristine code that has not been run yet appears with an empty box icon.\n",
        "\n",
        "![New code cell](https://github.com/christopherhuntley/DATA6510/raw/master/img/L1_code_cell_screenshot1.png)\n",
        "\n",
        "In this case, the code is in Python but as we will see Jupyter can run code in many different languages. Python just happens to be the default. We will be using *mostly* SQL in this class. \n",
        "\n",
        "To run the code, hover over the cell and press the circular run icon.\n",
        "\n",
        "![Run code cell](https://github.com/christopherhuntley/DATA6510/raw/master/img/L1_code_cell_screenshot2.png)\n",
        "\n",
        "After the code has been run (and you are no longer hovering over the cell), the box icon returns, this time with a number inside. \n",
        "\n",
        "![Output code cell](https://github.com/christopherhuntley/DATA6510/raw/master/img/L1_code_cell_screenshot3.png)\n",
        "\n",
        "The number indicates the order in which the cells in a notebook were run. It is possible to run the cells in a different order than they appear. That allows you to go back and debug things as you go along. However, you should also do a \"clean run\" (top-down after resetting the code cells) from time to time to be sure that the notebook works as written. \n",
        "\n",
        "Here, try it yourself.  The cell below is live. Run it. \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HND2pfazUebb"
      },
      "source": [
        "print('Hi There!')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KBOQO4tdd2mF"
      },
      "source": [
        "Congrats. For many of you this is your first Python code. We'll see a little more Python before we switch to SQL pretty much full time. \n",
        "\n",
        "In order to run SQL in Jupyter *without* Python, we will use [`ipython-sql`](https://github.com/catherinedevlin/ipython-sql), a Jupyter add-on that also goes by the name \"%sql magic.\" It does exactly what the name implies, doing all the hard work (i.e., magic) to interact with databases using just SQL. Recalling our earlier discussion of the three houses, %sql magic connections are like the Brick House with direct interactions with a remote database. \n",
        "\n",
        "We'll start with a tiny bit of Python to let Jupyter know that we are going to be using `ipython-sql`. The cell below, typically located near the top of the notebook, is used to enable (load) the %sql magic. Colab will let us now if it has already been loaded but there is no harm in loading it twice. \n",
        "\n",
        "![load sql magic](https://github.com/christopherhuntley/DATA6510/raw/master/img/L1_load_sql.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dChFs4OPih4J"
      },
      "source": [
        "With %sql magic loaded we can now create and run SQL queries in any code cell. First, however, we will need to tell %sql magic where to find the database we want to connect to. \n",
        "\n",
        "![SQLite in memory connection](https://github.com/christopherhuntley/DATA6510/raw/master/img/L1_sqlite_in_memory_connection.png)\n",
        "\n",
        "You'll notice that the part after `%sql` looks a bit like a web URL, with a protocol (`sqlite`) followed by `://`. That's no accident. We call this a **connection string**, which includes all the information (protocol, user, password, server, database) needed to find and then connect to the database, which can reside just about anywhere on the Internet. In this case, we are actually working directly with a database *in memory* (i.e., no network, no files, ... right inside your browser), a trick that is unique to SQLite, which was originally designed for embedded use in tiny devices without file systems. \n",
        "\n",
        "Once we have a database connection, we use the `%%sql` magic invocation (sort of like *abracadabra*) at the top of a code cell to indicate that all code after the first line is SQL. For example, the screenshot below includes a bit of SQL to create (or recreate) a table of customer profile data. \n",
        "\n",
        "![Create Table Example](https://github.com/christopherhuntley/DATA6510/raw/master/img/L1_create_table_example.png)\n",
        "\n",
        "Again, the text below the `%%sql` invocation is written in SQLite-compatible SQL. We will come back to this soon enough in the ***SQL AND BEYOND*** tutorial at the end of the lesson. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X0Cd3iF3CG2C"
      },
      "source": [
        "---\n",
        "## **Data Architecture: Entities, Attributes, Values, and Relationships**\n",
        "\n",
        "The figure belows show three different views of the same data:\n",
        "* A receipt from a dry cleaner order from January 2, 2019\n",
        "* An entity relationship diagram showing how the data is organized\n",
        "* A table of invoices from January 2, 2019\n",
        "\n",
        "In this section we explore data from the ground up, starting with basic definitions and issues, then moving on to data modeling and database design, and concluding with actual SQL code to implement the design.   \n",
        "\n",
        "![DeluxCare](https://github.com/christopherhuntley/DATA6510/raw/master/img/L1_DeluxCare.png)\n",
        "\n",
        "### **Data $\\rightarrow$ Information $\\rightarrow$ Knowledge**\n",
        "\n",
        "In data analytics we often treat \"data\" as a general term for whatever evidence we use to build and test models about the world. If it feeds our models then it's data. However, for the purposes of this course that sort of thinking is putting the cart before the horse. There is a lot of work needed before we can use data for our analyses, work that requires a somewhat more nuanced understanding of data. \n",
        "\n",
        "In its most fundamental form, **data is just facts that have been encoded so they can be stored.** The encoding itself is called a data type, of which there are many possibilities. Data may be unstructured text (\"Hi there!\"), categorical labels (red, blue, green), numerical quantities (ordinal, integer, rational, real), coordinates (latitude/longitude), images (bitmapped pixels, jpg, png, etc.) or even just a blob of binary data. If it can be stored, then it is data.\n",
        "\n",
        "**Information is data that has meaning.** So, while the location `41.1588° N, 73.2574° W` is data, it is not very informative until we note that it is where we would find Fairfield University on a map. We give data meaning by providing **metadata (\"data about data\")** about the context. Metadata includes things like the data type, what the data represents, when the data was recorded, and cross-references to related data that can further provide context. If we can interpret it, then data is information. \n",
        "\n",
        "**Knowledge is how we use information to do things.** The data models that we build are knowledge. They convert information into actionable insights. So, if we were creating a routing algorithm to get to the Fairfield University from anywhere else in the world, we would need information about the starting  location, maps that capture the possible pathways for different kinds of transportation, and perhaps a desired arrival time. The routing algorithm is the knowledge, the rest is information. \n",
        "\n",
        "**Database systems are designed to manage information and make it available to other apps.** At a minimum they:\n",
        "- Store facts as persistent data\n",
        "- Structure the facts with metadata (stored with the data)\n",
        "- Allow access to the data for use by other systems (CRUD operations)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SAixkYSyINTV"
      },
      "source": [
        "### **Data Integrity: Do you really know what's in the data you're consuming?**\n",
        "\n",
        "Converting data into useful information is hard work. It is often estimated that as much 80% of data analytics work is wrangling with data to prep it for use. If the dataset is small and the analytical models fairly simple, then we might barely notice having to clean up missing data, typos, or other problems. However, once the datasets get larger, the problems get bigger as well. We will cover many of these problems in Lessons 4 and 9. For now, just know that as datasets get larger, the odds of running into every possible kind of data problem increase. For really big datasets, the odds are virtually 100% that there is at least one serious data problem to resolve before moving on to analytical modeling.  \n",
        "\n",
        "From a database perspective, where we don't always know exactly how the data will be used, we focus on three kinds of **data integrity**:\n",
        "\n",
        "- **Domain integrity** is about how facts are encoded. Is it in a way that makes sense for potential uses? Can an expert in the field recognize and interpret the data in a meaningful way? \n",
        "- **Entity integrity** is about data storage and retrieval. If we are seeking the facts for a given situation, can we retrieve just those facts and no others? \n",
        "- **Referential integrity** is about how facts relate to each other. Do any and all cross-references connect the right facts? Are there any invalid cross-references that point to missing data? Are any required relationships missing entirely?  \n",
        "\n",
        "One of the most frustrating things about data integrity is that it tends to degrade over time:\n",
        "- People's understanding of the data may shift, invalidating domain integrity.\n",
        "- Identifiers like names may change, making it hard to find exactly what is needed.\n",
        "- Data is continually being added, updated, or deleted, with each transaction potentially causing a referential integrity error. \n",
        "This is sort of like the database version of **entropy**, the law of physics that suggests that the universe will eventually wind up as a totally disorganized mess. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4OmXwHsRDraR"
      },
      "source": [
        "### **Data Models ... Once and Forever**\n",
        "\n",
        "Maintaining data integrity is an active process that requires continual evolution of the database itself. So, while it would be great to just think about data retrieval (i.e., SQL SELECTS), in this course we will by necessity spend a lot of time on **database design** and how to maintain databases using SQL CREATE, INSERT, UPDATE, and DELETE commands. \n",
        "\n",
        "All design starts and ends with modeling. In database design we focus on three kinds of data models:\n",
        "- **Conceptual models** (diagrams) that permit visualization of the database structure before it is built. These are like blueprints for the database. \n",
        "- **Logical models** (programs) that define processes for building, using, and maintaining the database. \n",
        "- **Physical models** (technology) that define how the databases operate on real-world hardware. \n",
        "\n",
        "We will cover conceptual modeling in Lessons 5, 6, 9 and 10, Logical modeling in Lessons 4, 7 and 8, and Physical models in Lessons 11 and 12. However, we will conclude this section with a few essentials to get us started. \n",
        "\n",
        "#### **Conceptual Models**\n",
        "The primary conceptual model used by database designers is the Entity Relationship Diagram (ERD). Interestingly, ERDs are not actually about data so much as the things (entities) the data is meant to describe. An **entity** is a *specific* thing we capture data about. Typically, the entity has a name or number that acts as an **unique identifier**; if any two things share the same identifier then neither is an entity. The facts that we attach to an entity are called **attributes**. Some attributes are special, used to refer to other entities, usually of a different type. \n",
        "\n",
        "In the DeluxCare ERD below there are three types of entities (Customers, Invoices, and Garments), each shown as a rounded box. The name of the entity type is shown as a label at the top of the box. The attributes are then listed in the bottom portion of the box. If an attribute is to be used as an identifier then it has a `PK` (for *primary key*) listed to its left. Attributes that are used as cross-references are list with an `FK` (for *foreign key*) next to them. The nature of the relationships between the entities are specified with special notations at either end of the connecting lines. So, for example, the line connecting `Customer` to `Invoice`  specifies that each customer has zero or more invoices and that each invoice must relate to exactly one customer. (In fact, the `customer_id` foreign key on the Invoice entity is there because of the relationship. However, there is no corresponding `invoice_id` foreign key on the Customer entity. Why do you suppose that is?)\n",
        "\n",
        "![DeluxCare ERD](https://github.com/christopherhuntley/DATA6510/raw/master/img/L1_DeluxCare_erd.png)\n",
        "\n",
        "#### **Logical Models**\n",
        "\n",
        "Logical design focuses on two artifacts: \n",
        "- the tables that correspond to the entities in the ERDs\n",
        "- the SQL code necessary to create the tables in the database\n",
        "\n",
        "Since we will be working with live SQL in the next section, we will for now just consider table design. \n",
        "\n",
        "SQL database logic is said to be **relational**, which is a fancy way of the data is organized into tables where:\n",
        "- Each table corresponds to a given entity type\n",
        "- Each row of the table corresponds to one *instance* of the entity type \n",
        "- Each column contains one attribute (fact) for the instance\n",
        "- Row and column order do not affect data meaning\n",
        "- Each row has one (or more) column(s) called a *primary key* that can be used to retrieve the row after it is created\n",
        "- Any cross-references are implemented as *foreign key* attributes that indicate the primary key value of the entity being referenced. Note: a table does not have to have a foreign key. \n",
        "\n",
        "The design of the `invoices` table for the DeluxCare database is shown below. \n",
        "\n",
        "![DeluxCare Invoices Table](https://github.com/christopherhuntley/DATA6510/raw/master/img/L1_DeluxCare_invoices_table.png)\n",
        "\n",
        "#### **Physical Models**\n",
        "The physical model of a given database is somewhat vendor-specific. Each DBMS vendor provides different options, depending on the needs of their customers. Here we will focus on just two of the many of the possible physical design decisions behind a given DBMS. Both relate to how data redundancy is used to make the database more reliable and performant. \n",
        "\n",
        "The first decision is how the data is stored and backed up. One option is to keep the data in files on a local hard drive. MySQL, for example, stores each table as a single file buried somewhere on a hard disk. SQLite does something similar, except in a location of the user's choosing. In either case, one can back up the data by copying the actual database files, along with perhaps some metadata about the files themselves. The alternative to locally-accessible files is to hide all storage implementation behind a service, which may be the database management system itself. In this case, backups are often retrieved as SQL 'dump files' that contain instructions for recreating the data from scratch. Of course, since the server is managed by the vendor, they may also offer a paid backup service that uses proprietary technology of their own design.\n",
        "\n",
        "The second decision is how many live copies of the data to keep. The classic approach is to use a centralized database server. In this case there is only one live copy of the data to secure, backup, etc. However, this can cause delays for remote users, where each DB request and response may have to travel a long route through the Internet, causing significant latency for the end users. The solution is to use a decentralized architecture, with multiple copies of the database distributed close to the end users. It is then the database system's job to keep the various copies in sync so that two users on opposite sides of the world aren't working with different \"facts\" for the same entities.  \n",
        "\n",
        "We will come back to these issues in Lesson 12 at the end of the course. \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e0ZFvcZJTPMF"
      },
      "source": [
        "---\n",
        "## **PRO TIPS: How to pare a data model to its bare essentials**\n",
        "\n",
        "Data modeling is about capturing the essence of the _things_ around us. What are they? What do they look (or feel or sound ...) like? What are they made of? What are they doing? What is acting on them? There are just so many questions to answer. \n",
        "\n",
        "However, everything starts with the *things* themselves. Anything that could be referred to with a noun is a potential thing that produces data. Further, since nouns are used as subjects and objects, anything described with a verb phrase is also a candidate for data collection. In just about any real-life situation one can generate a veritable mountain of data just by studying the things around us. \n",
        "\n",
        "So, where do we start? How do we keep our data to just the facts we need to know? Fortunately, we are not the first people to ask that question and there is plenty of practical philosophy to draw on. Here we'll cover a few of the best practices as a set of useful contrasts. \n",
        "\n",
        "### **Dynamic vs Static**\n",
        "When observing a situation, it is often useful to take \"snapshots\" and then look for two kinds of facts:\n",
        "\n",
        "- **Dynamic elements: Facts that change from frame to frame.** What key differences do you see over time? These changes hint at underlying processes. The changes themselves are called *events*. If the dynamic elements you detect are relevant, then capture the events so you can recreate the patterns over time. \n",
        "- **Static elements: Facts that do not change at all, ever.** These may be key structural elements that help us understand or predict the behaviors of the dynamic elements. In many cases they represent the essential makeup or composition of the entities we are interested in. \n",
        "\n",
        "**Wisdom:** When observing a situation, ask yourself what things you would need to know to simulate it. Focus your observations on things that change and things constrain the changes. The right data will be in there somewhere. \n",
        "\n",
        "### **Entities vs Data Objects**\n",
        "As we have already discussed, entities are things that have unique identities. They are the things we need to capture data about. But what about the other things that are not entities? Either they are just noise to be ignored or they are **value objects** that make up the attributes of the entities. Every attribute has a data type and can take on some range of values. **These data objects are the things that make up the attribute ranges.** Often this is a matter of context. The color \"brown,\" for example, might be an entity in a physics lab but is a value object when cited as hair color on a driver's license. \n",
        "\n",
        "**Wisdom:** Don't just ignore data objects. Instead, ask what attributes they represent and what entities have those attributes. \n",
        "\n",
        "### **Abstraction vs Specification**\n",
        "Often the same thing can go by many different names. What is the essential difference between a car and an automobile? Or between employee and staff? \n",
        "\n",
        "Abstraction is about finding similarities. When faced with such fine distinctions that may not be relevant to your needs, it is common practice to aggregate similar things together into groups as a matter of efficiency. If they behave the same then why treat them differently? Instead, we abstract away the irrelevant differences and then isolate (specify) the relevant ones. To keep our specifications coherent we'll often invent new names for the entities and value objects so generated. \n",
        "\n",
        "This process of generalization and specification follows a cyclical pattern, where we look to generalize away specifics that don't matter and then specify what facts remain. We do it every day but expert data modelers do it better. \n",
        "\n",
        "**Wisdom:** Names and relationships matter. Try to standardize your language in ways that allow people to generalize and specify as needed. \n",
        "\n",
        "### **Data vs Database**\n",
        "\n",
        "When capturing data it is easy to confuse database technology with the data itself. We use database technology to store and maintain data. However, the database is not the data. It's like the difference between your wallet and the data it contains. When you lose your wallet, you may lose some cash, credit cards, etc. (where data takes physical form) but you don't actually lose the right to drive or your accounts. \n",
        "\n",
        "**Wisdom:** Eliminate technical jargon whenever you can. If you can't imagine a person working in the field using a phrase in everyday speech, then it is likely not relevant. So, unless the business domain is IT, avoid using terms like \"repository\" or \"key\" or \"server\" that only make sense to IT folks. \n",
        "\n",
        "### **Conclusion: Start big, then pare down and stick with what works**\n",
        "\n",
        "The above bits of wisdom only apply once you have captured plenty of facts. So, be expansive at first, taking in whatever you can. Then make an active effort to eliminate all nonessential details. You want a cohesive whole made of a minimal number of interconnected entity types where ...\n",
        "- Each entity is as simple as possible\n",
        "- Each attribute is as relevant and relatable as you can make it\n",
        "- Each relationship is as precise as you can make it\n",
        "\n",
        "**If we find ourselves continually changing out data models then we are just not doing it right. Essentials are eternal and *never* change. If they do then they are *accidental* instead of essential. Keep it simple and consistent over time.** "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FLaBKSEvJ7Fy"
      },
      "source": [
        "---\n",
        "## **SQL AND BEYOND: SQLite ... Files optional, no server required** \n",
        "\n",
        "We have already been introduced to SQLite a couple of times in this lesson. Now let's go deeper with a runnable demonstration. \n",
        "\n",
        "### **What Is SQLite?**\n",
        "\n",
        "From the [SQLite.org](https://sqlite.org/index.html) website:\n",
        ">SQLite is a C-language library that implements a small, fast, self-contained, high-reliability, full-featured, SQL database engine. SQLite is the most used database engine in the world. SQLite is built into all mobile phones and most computers and comes bundled inside countless other applications that people use every day. More Information...\n",
        ">\n",
        ">The SQLite file format is stable, cross-platform, and backwards compatible and the developers pledge to keep it that way through the year 2050. SQLite database files are commonly used as containers to transfer rich content between systems [1] [2] [3] and as a long-term archival format for data [4]. There are over 1 trillion (1e12) SQLite databases in active use [5].\n",
        ">\n",
        ">SQLite source code is in the public-domain and is free to everyone to use for any purpose.\n",
        "\n",
        "There is a lot to parse there. Some highlights:\n",
        "\n",
        "- Implemented in C for maximum speed and minimal installation footprint. \n",
        "- Very, very popular with device makers of all sorts, with over 1 trillion SQLite databases in use. \n",
        "- Stores data in files or in memory (as mentioned earlier in the lesson). \n",
        "- Minimal file size allows it to be used as a transfer container for shipping large data repositories from one place to another. \n",
        "- There is no DBMS per se. Remote access, security protections, etc. have to be provided through a separate application server. \n",
        "\n",
        "In this class we are using the `sqlite3` Python library that comes built into Jupyter, which when combined with `%%sql` magic is the most convenient way to work with relational data in Colab. \n",
        "\n",
        "What follows is a step-by-step tutorial. Each step has a brief explanation in Markdown followed by a code cell with some Python code for you to run. Don't know Python? Don't worry. Your job is to run the cells, not write Python code (yet?).\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "th6x2R_lE4-C"
      },
      "source": [
        "### **1. Complete a few admin tasks.**\n",
        "\n",
        "Before we can do much with queries, we'll need to do some administrative tasks in Google Drive.  Some cells may fail if it finds something it doesn't expect like ...\n",
        "- You are using a browser other than Chrome. \n",
        "- Chrome thinks you are in something other than your `@student.fairfield.edu` account. \n",
        "- Colab thinks you are in something other than your `@student.fairfield.edu` account.\n",
        "- Your Google Drive is not set up for Google Colab and DATA 6510 as directed in Lesson 0. \n",
        "- The necessary data files could not be found at GitHub.\n",
        "- Google Drive is being *really slow*. \n",
        "Don't worry. Each of these things can usually be resolved in a few minutes. Ask for help on Slack if needed.\n",
        "\n",
        "Run each code cell, one at a time, reading any notes provided (above or below the cell) that explain what the code is doing. \n",
        "\n",
        "#### **1a. Set up a workspace in Google Drive for our database files.**\n",
        "\n",
        "The cell below connects to Google Drive and adds a folder to store our new files.  \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qx0miHidOgl3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16447556-c12a-4cb5-c836-d6983ff8779c"
      },
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Create the DATA6510/data/DeluxCare folder in Google Drive\n",
        "from pathlib import Path\n",
        "data_root = Path(\"./drive/My Drive/Colab Notebooks/DATA6510\")\n",
        "if not data_root.exists():\n",
        "  print(\n",
        "      '''\n",
        "      Warning! The folder '/Colab Notebooks/DATA6510' could not be found in the connected Google Drive. \n",
        "      Please make 100% sure that both Colab and Chrome are set up use your @student.fairfield.edu account. \n",
        "      For now, a new folder with the correct path has been created in whatever Google Drive it found. \n",
        "      ''')\n",
        "data_root = data_root / 'data' / 'DeluxCare'\n",
        "data_root.mkdir(parents=True, exist_ok=True)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M-0s4h_EY1LU"
      },
      "source": [
        "The cell below makes a `data6510` symlink (\"shortcut\") to the `DATA6510` folder that works around spaces in the folder names (`My Drive`, `Colab Notebooks`, etc.). FWIW, `bash` is a commonly used shell environment for Unix and Linux servers. It's what you see by default in the MacOS Terminal.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9f-HiSR3YwbE"
      },
      "source": [
        "%%bash\n",
        "ln -s drive/My\\ Drive/Colab\\ Notebooks/DATA6510 data6510"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i_ZEj8eyah-7"
      },
      "source": [
        "**Heads up: We will need to refresh the Google Drive connections and the symlink for each SQLite session. Colab forgets about all file related things between sessions. If you've been away for 12 hours or more then expect to have to set up Google Drive and the symlink again. All you'll need to do is rerun the cells provided, usually at the top of the notebook for each lesson.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ofp3a1XlCrMk"
      },
      "source": [
        "#### **1b. Retrieve source data and store it in Google Drive.**\n",
        "\n",
        "This cell downloads a copy of the database from GitHub and saves it to Google Drive. The database contains data about every sale (invoice) in 2019 for the DeluxCare dry cleaner business. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sxjZif_aCkM2"
      },
      "source": [
        "import requests  \n",
        "file_url = \"https://github.com/christopherhuntley/DATA6510/raw/master/data/DeluxCare/L1_DeluxCare.db\"\n",
        "r = requests.get(file_url, stream = True)  \n",
        "\n",
        "db_path = data_root / \"L1_DeluxCare.db\" # note: data_root was set in 1a. \n",
        "with open(db_path, \"wb\") as file:  \n",
        "    for block in r.iter_content(chunk_size = 1024): \n",
        "         if block:  \n",
        "             file.write(block)\n",
        "\n",
        " "
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bSZGzc_mDKC3"
      },
      "source": [
        "### **2. Connect to the Database**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nVjy4HPBOE2t"
      },
      "source": [
        "#### **2a. Let Colab know that we will be using `%%sql` magic, `sqlite3`, and (possibly) pandas.**\n",
        "\n",
        "This cell is mostly 'boilerplate' that we will run at the start of just about every lesson from now on. \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cRXCWH6uOLKW"
      },
      "source": [
        "# Load %%sql magic\n",
        "%load_ext sql\n",
        "\n",
        "# Standard Imports\n",
        "import sqlite3\n",
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hBUlkMl7G6kX"
      },
      "source": [
        "#### **2b. Initiate and test a SQLite connection.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sfjal0FqZEsV"
      },
      "source": [
        "The cell below uses a special *connection string* to 'open' the database file for querying. Connection strings follow the [SqlAlchemy Database URL standards](https://docs.sqlalchemy.org/en/14/core/engines.html#database-urls). For SQLite the format is `sqlite:///path/to/file` where `path/to/file` is a valid filepath *without spaces*. We used the symlink in step 1a to avoid the spaces.  Most of the time connection URLs will be provided for you, but you should still pay attention to the way they are structured. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lcnOu4x5HXTY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "85d693e8-76f0-4eff-b94a-c5805d07b1fd"
      },
      "source": [
        "%sql sqlite:///data6510/data/DeluxCare/L1_DeluxCare.db"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Connected: @data6510/data/DeluxCare/L1_DeluxCare.db'"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Ut5XORGZbp5"
      },
      "source": [
        "The cell below makes sure that the connection worked. It should return metadata listing the names and columns for two tables. The SQL shown is the actual code needed to create the table in the database. (The SQL indentation is off, by the way. We will learn to do it properly in Lesson 7.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oV0pXv-RQM5v",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 388
        },
        "outputId": "9c758930-42e6-4e57-f8d3-893a88e09740"
      },
      "source": [
        "%%sql\n",
        "SELECT * FROM sqlite_master"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " * sqlite:///data6510/data/DeluxCare/L1_DeluxCare.db\n",
            "Done.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<table>\n",
              "    <thead>\n",
              "        <tr>\n",
              "            <th>type</th>\n",
              "            <th>name</th>\n",
              "            <th>tbl_name</th>\n",
              "            <th>rootpage</th>\n",
              "            <th>sql</th>\n",
              "        </tr>\n",
              "    </thead>\n",
              "    <tbody>\n",
              "        <tr>\n",
              "            <td>table</td>\n",
              "            <td>customers</td>\n",
              "            <td>customers</td>\n",
              "            <td>2</td>\n",
              "            <td>CREATE TABLE customers (<br>    customer_id INTEGER PRIMARY KEY,<br>    first_date TIMESTAMP,<br>    last_date TIMESTAMP<br>)</td>\n",
              "        </tr>\n",
              "        <tr>\n",
              "            <td>table</td>\n",
              "            <td>invoices</td>\n",
              "            <td>invoices</td>\n",
              "            <td>3</td>\n",
              "            <td>CREATE TABLE invoices (<br>    invoice_id INTEGER PRIMARY KEY,<br>    customer_id INTEGER,<br>    date_invoice TIMESTAMP,<br>    date_finished TIMESTAMP,<br>    date_paid TIMESTAMP,<br>    date_pickup TIMESTAMP,<br>    date_ready TIMESTAMP,<br>    total REAL,<br>    discount REAL,<br>    prepaid REAL,<br>    items INTEGER<br>)</td>\n",
              "        </tr>\n",
              "    </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "[('table', 'customers', 'customers', 2, 'CREATE TABLE customers (\\n    customer_id INTEGER PRIMARY KEY,\\n    first_date TIMESTAMP,\\n    last_date TIMESTAMP\\n)'),\n",
              " ('table', 'invoices', 'invoices', 3, 'CREATE TABLE invoices (\\n    invoice_id INTEGER PRIMARY KEY,\\n    customer_id INTEGER,\\n    date_invoice TIMESTAMP,\\n    date_finished TIMESTAMP,\\n   ... (6 characters truncated) ... _paid TIMESTAMP,\\n    date_pickup TIMESTAMP,\\n    date_ready TIMESTAMP,\\n    total REAL,\\n    discount REAL,\\n    prepaid REAL,\\n    items INTEGER\\n)')]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ni4JNaUcZzuM"
      },
      "source": [
        "### **3. Finally, we get to run some SQL queries.**\n",
        "\n",
        "Now that we have access to the database let's explore a bit to see what we have. We'll title each query as a question. The code cells then answer the questions. Don't forget to run the code before reading the remarks. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NmtW9rA7hrPZ"
      },
      "source": [
        "#### **How many customers are in the database?**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OOAHTR7-doww",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 95
        },
        "outputId": "6c1f4be3-9c97-4b0d-f0a6-4c460e540504"
      },
      "source": [
        "%%sql\n",
        "SELECT count(DISTINCT customer_id) \n",
        "FROM customers;"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " * sqlite:///data6510/data/DeluxCare/L1_DeluxCare.db\n",
            "Done.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<table>\n",
              "    <thead>\n",
              "        <tr>\n",
              "            <th>count(DISTINCT customer_id)</th>\n",
              "        </tr>\n",
              "    </thead>\n",
              "    <tbody>\n",
              "        <tr>\n",
              "            <td>4169</td>\n",
              "        </tr>\n",
              "    </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "[(4169,)]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3B5DSnqMeo7h"
      },
      "source": [
        "REMARKS: \n",
        "- Not every customer is a person. Some represent hotels or other businesses.  \n",
        "- Like all of the queries in this lesson, we are using a `SELECT` statement. The `FROM` clause tells the query what tables to use. \n",
        "- The query counts the number of unique (`DISTINCT`) `customer_id` values that appear in the `customers` table. Since `customer_id` is the primary key of the `customers` table, they are each unique and we do not actually need to use `DISTINCT`.\n",
        "\n",
        "ANSWER: There are over 4169 customer accounts in the database. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3hUS7JM5d5OE"
      },
      "source": [
        "#### **Which are the oldest customer accounts?**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_XRNbqMfePio",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        },
        "outputId": "a4b70e9b-e9f1-470d-d409-c0b1196ba084"
      },
      "source": [
        "%%sql\n",
        "SELECT * \n",
        "FROM customers\n",
        "ORDER BY first_date\n",
        "LIMIT 10; "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " * sqlite:///data6510/data/DeluxCare/L1_DeluxCare.db\n",
            "Done.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<table>\n",
              "    <thead>\n",
              "        <tr>\n",
              "            <th>customer_id</th>\n",
              "            <th>first_date</th>\n",
              "            <th>last_date</th>\n",
              "        </tr>\n",
              "    </thead>\n",
              "    <tbody>\n",
              "        <tr>\n",
              "            <td>1</td>\n",
              "            <td>None</td>\n",
              "            <td>2019-02-13 00:00:00</td>\n",
              "        </tr>\n",
              "        <tr>\n",
              "            <td>2</td>\n",
              "            <td>1899-12-30 00:00:00</td>\n",
              "            <td>2019-04-06 00:00:00</td>\n",
              "        </tr>\n",
              "        <tr>\n",
              "            <td>3</td>\n",
              "            <td>1899-12-30 00:00:00</td>\n",
              "            <td>2020-03-16 00:00:00</td>\n",
              "        </tr>\n",
              "        <tr>\n",
              "            <td>4</td>\n",
              "            <td>1899-12-30 00:00:00</td>\n",
              "            <td>2019-12-30 00:00:00</td>\n",
              "        </tr>\n",
              "        <tr>\n",
              "            <td>5</td>\n",
              "            <td>1997-02-19 00:00:00</td>\n",
              "            <td>2019-05-08 00:00:00</td>\n",
              "        </tr>\n",
              "        <tr>\n",
              "            <td>6</td>\n",
              "            <td>1997-02-19 00:00:00</td>\n",
              "            <td>2019-12-30 00:00:00</td>\n",
              "        </tr>\n",
              "        <tr>\n",
              "            <td>7</td>\n",
              "            <td>1997-03-11 00:00:00</td>\n",
              "            <td>2020-03-06 00:00:00</td>\n",
              "        </tr>\n",
              "        <tr>\n",
              "            <td>8</td>\n",
              "            <td>1997-03-11 00:00:00</td>\n",
              "            <td>2019-01-16 00:00:00</td>\n",
              "        </tr>\n",
              "        <tr>\n",
              "            <td>9</td>\n",
              "            <td>1997-03-11 00:00:00</td>\n",
              "            <td>2019-02-08 00:00:00</td>\n",
              "        </tr>\n",
              "        <tr>\n",
              "            <td>10</td>\n",
              "            <td>1997-03-11 00:00:00</td>\n",
              "            <td>2020-03-09 00:00:00</td>\n",
              "        </tr>\n",
              "    </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "[(1, None, '2019-02-13 00:00:00'),\n",
              " (2, '1899-12-30 00:00:00', '2019-04-06 00:00:00'),\n",
              " (3, '1899-12-30 00:00:00', '2020-03-16 00:00:00'),\n",
              " (4, '1899-12-30 00:00:00', '2019-12-30 00:00:00'),\n",
              " (5, '1997-02-19 00:00:00', '2019-05-08 00:00:00'),\n",
              " (6, '1997-02-19 00:00:00', '2019-12-30 00:00:00'),\n",
              " (7, '1997-03-11 00:00:00', '2020-03-06 00:00:00'),\n",
              " (8, '1997-03-11 00:00:00', '2019-01-16 00:00:00'),\n",
              " (9, '1997-03-11 00:00:00', '2019-02-08 00:00:00'),\n",
              " (10, '1997-03-11 00:00:00', '2020-03-09 00:00:00')]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bbTaQwUoeynz"
      },
      "source": [
        "REMARKS: \n",
        "\n",
        "- This is 100% real data. The customer names, addresses, and other identifying information were scrubbed to protect customer privacy. \n",
        "- Customer 1 actually is a special account used to handle cash transactions that do not have a proper invoice. That's why it does not have a first_date. \n",
        "- Similarly, customers 2, 3, and 4 represent industrial accounts that predate the system. December 30, 1899 is the earliest date the POS system could handle.\n",
        "- All dates are encoded as TIMESTAMPs that include the time of day. In this case, they are all treated as happening at midnight. \n",
        "- The `ORDER BY` clause sorts the data using the `first_date` column. \n",
        "- The `LIMIT` clause tells the query to return up to 10 rows of data.   \n",
        "\n",
        "ANSWER:  Customers 5 and 6 have the longest-running customer accounts. Both were created on February 2, 1997. The oldest account with activity in 2020 was customer 7. It really is remarkable how loyal these customers have been over the years. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OZj2p0mMi8Kh"
      },
      "source": [
        "#### **How many transactions (invoices) did customer 5 have in 2019?**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IH_OkxwYjTrh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 95
        },
        "outputId": "c3f74efd-84e6-4cf7-861a-f7916da91d3a"
      },
      "source": [
        "%%sql\n",
        "SELECT count(invoice_id) \n",
        "FROM invoices\n",
        "WHERE customer_id=5;"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " * sqlite:///data6510/data/DeluxCare/L1_DeluxCare.db\n",
            "Done.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<table>\n",
              "    <thead>\n",
              "        <tr>\n",
              "            <th>count(invoice_id)</th>\n",
              "        </tr>\n",
              "    </thead>\n",
              "    <tbody>\n",
              "        <tr>\n",
              "            <td>2</td>\n",
              "        </tr>\n",
              "    </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "[(2,)]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HA6lMFHGjl9M"
      },
      "source": [
        "REMARKS:\n",
        "\n",
        "- We had to use the `invoices` table to answer this question. Each invoice has an `invoice_id` (primary key) and a `customer_id` (foreign key). \n",
        "- The `WHERE` clause restricts the rows included in the query to just those with `customer_id` equal to 5. \n",
        "\n",
        "ANSWER: Customer 5 had two transactions in 2019."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sYRazQBqmIub"
      },
      "source": [
        "#### **Which customers had the most transactions in 2019?**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5IqujptymSDV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        },
        "outputId": "489de815-9d2e-4474-8d82-ba8ceea3feb2"
      },
      "source": [
        "%%sql\n",
        "SELECT customer_id, count(invoice_id) as invoice_count\n",
        "FROM invoices\n",
        "GROUP BY customer_id\n",
        "ORDER BY invoice_count DESC\n",
        "LIMIT 10;"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " * sqlite:///data6510/data/DeluxCare/L1_DeluxCare.db\n",
            "Done.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<table>\n",
              "    <thead>\n",
              "        <tr>\n",
              "            <th>customer_id</th>\n",
              "            <th>invoice_count</th>\n",
              "        </tr>\n",
              "    </thead>\n",
              "    <tbody>\n",
              "        <tr>\n",
              "            <td>1708</td>\n",
              "            <td>508</td>\n",
              "        </tr>\n",
              "        <tr>\n",
              "            <td>2598</td>\n",
              "            <td>412</td>\n",
              "        </tr>\n",
              "        <tr>\n",
              "            <td>1147</td>\n",
              "            <td>400</td>\n",
              "        </tr>\n",
              "        <tr>\n",
              "            <td>2300</td>\n",
              "            <td>381</td>\n",
              "        </tr>\n",
              "        <tr>\n",
              "            <td>2090</td>\n",
              "            <td>379</td>\n",
              "        </tr>\n",
              "        <tr>\n",
              "            <td>2925</td>\n",
              "            <td>338</td>\n",
              "        </tr>\n",
              "        <tr>\n",
              "            <td>445</td>\n",
              "            <td>337</td>\n",
              "        </tr>\n",
              "        <tr>\n",
              "            <td>1164</td>\n",
              "            <td>323</td>\n",
              "        </tr>\n",
              "        <tr>\n",
              "            <td>2061</td>\n",
              "            <td>323</td>\n",
              "        </tr>\n",
              "        <tr>\n",
              "            <td>1975</td>\n",
              "            <td>276</td>\n",
              "        </tr>\n",
              "    </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "[(1708, 508),\n",
              " (2598, 412),\n",
              " (1147, 400),\n",
              " (2300, 381),\n",
              " (2090, 379),\n",
              " (2925, 338),\n",
              " (445, 337),\n",
              " (1164, 323),\n",
              " (2061, 323),\n",
              " (1975, 276)]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WFEqwuOom1Ae"
      },
      "source": [
        "REMARKS\n",
        "\n",
        "- This query is 100% equivalent to an Excel pivot table. \n",
        "- The `AS` keyword gives the calculation `count(invoice_id)` an alias (name)`invoice_count` that we can use later. \n",
        "- The `GROUP BY` clause tells the query to do sub-counts broken down by `customer_id`.\n",
        "- The `ORDER BY` clause sorts the groups in descending order (`DESC`) by `invoice_count`.\n",
        "\n",
        "ANSWER: It looks like customer 1708 is the winner. Like the others on this list, it most certainly represents an industrial account. After all, who else goes to the cleaners multiple times per day?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BT9rWV8Oosqq"
      },
      "source": [
        "#### **For each of the top 10 customers, how long have they been customers?**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dl5gAotXo9Tr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        },
        "outputId": "154da4a2-0767-4af7-a910-338edf757d00"
      },
      "source": [
        "%%sql\n",
        "SELECT customer_id, date(first_date) as start_date, count(invoice_id) as invoice_count\n",
        "FROM invoices JOIN customers USING (customer_id)\n",
        "GROUP BY customer_id, first_date\n",
        "ORDER BY invoice_count DESC\n",
        "LIMIT 10;"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " * sqlite:///data6510/data/DeluxCare/L1_DeluxCare.db\n",
            "Done.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<table>\n",
              "    <thead>\n",
              "        <tr>\n",
              "            <th>customer_id</th>\n",
              "            <th>start_date</th>\n",
              "            <th>invoice_count</th>\n",
              "        </tr>\n",
              "    </thead>\n",
              "    <tbody>\n",
              "        <tr>\n",
              "            <td>1708</td>\n",
              "            <td>2008-11-24</td>\n",
              "            <td>508</td>\n",
              "        </tr>\n",
              "        <tr>\n",
              "            <td>2598</td>\n",
              "            <td>2016-04-20</td>\n",
              "            <td>412</td>\n",
              "        </tr>\n",
              "        <tr>\n",
              "            <td>1147</td>\n",
              "            <td>2005-03-21</td>\n",
              "            <td>400</td>\n",
              "        </tr>\n",
              "        <tr>\n",
              "            <td>2300</td>\n",
              "            <td>2014-02-06</td>\n",
              "            <td>381</td>\n",
              "        </tr>\n",
              "        <tr>\n",
              "            <td>2090</td>\n",
              "            <td>2012-07-02</td>\n",
              "            <td>379</td>\n",
              "        </tr>\n",
              "        <tr>\n",
              "            <td>2925</td>\n",
              "            <td>2018-01-02</td>\n",
              "            <td>338</td>\n",
              "        </tr>\n",
              "        <tr>\n",
              "            <td>445</td>\n",
              "            <td>1999-03-02</td>\n",
              "            <td>337</td>\n",
              "        </tr>\n",
              "        <tr>\n",
              "            <td>1164</td>\n",
              "            <td>2005-05-10</td>\n",
              "            <td>323</td>\n",
              "        </tr>\n",
              "        <tr>\n",
              "            <td>2061</td>\n",
              "            <td>2012-03-26</td>\n",
              "            <td>323</td>\n",
              "        </tr>\n",
              "        <tr>\n",
              "            <td>1975</td>\n",
              "            <td>2011-07-20</td>\n",
              "            <td>276</td>\n",
              "        </tr>\n",
              "    </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "[(1708, '2008-11-24', 508),\n",
              " (2598, '2016-04-20', 412),\n",
              " (1147, '2005-03-21', 400),\n",
              " (2300, '2014-02-06', 381),\n",
              " (2090, '2012-07-02', 379),\n",
              " (2925, '2018-01-02', 338),\n",
              " (445, '1999-03-02', 337),\n",
              " (1164, '2005-05-10', 323),\n",
              " (2061, '2012-03-26', 323),\n",
              " (1975, '2011-07-20', 276)]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0-w7MqjvpcoG"
      },
      "source": [
        "REMARKS\n",
        "\n",
        "- We had to get data from both tables to answer this one. \n",
        "- We used the `date()` function (and an alias) to convert the `TIMESTAMP` data to dates without the time of day. \n",
        "- The `JOIN` expression in the `FROM` clause matches each invoice with a customer `USING` the `customer_id`. \n",
        "- The `customer_id` was included in the `GROUP BY` so that it could be used in the `SELECT` clause. Some DBMS's don't require this precaution but it's better to be safe than sorry. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t_j9XhTGqddW"
      },
      "source": [
        "#### **That last one is hard to read. Can we have it as a nicely formatted table?**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kVroJsDIqliH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "outputId": "07fc1b5c-7f1d-41e7-a1a5-21cb15248231"
      },
      "source": [
        "_.DataFrame()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>customer_id</th>\n",
              "      <th>start_date</th>\n",
              "      <th>invoice_count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1708</td>\n",
              "      <td>2008-11-24</td>\n",
              "      <td>508</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2598</td>\n",
              "      <td>2016-04-20</td>\n",
              "      <td>412</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1147</td>\n",
              "      <td>2005-03-21</td>\n",
              "      <td>400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2300</td>\n",
              "      <td>2014-02-06</td>\n",
              "      <td>381</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2090</td>\n",
              "      <td>2012-07-02</td>\n",
              "      <td>379</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>2925</td>\n",
              "      <td>2018-01-02</td>\n",
              "      <td>338</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>445</td>\n",
              "      <td>1999-03-02</td>\n",
              "      <td>337</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>1164</td>\n",
              "      <td>2005-05-10</td>\n",
              "      <td>323</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>2061</td>\n",
              "      <td>2012-03-26</td>\n",
              "      <td>323</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>1975</td>\n",
              "      <td>2011-07-20</td>\n",
              "      <td>276</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   customer_id  start_date  invoice_count\n",
              "0         1708  2008-11-24            508\n",
              "1         2598  2016-04-20            412\n",
              "2         1147  2005-03-21            400\n",
              "3         2300  2014-02-06            381\n",
              "4         2090  2012-07-02            379\n",
              "5         2925  2018-01-02            338\n",
              "6          445  1999-03-02            337\n",
              "7         1164  2005-05-10            323\n",
              "8         2061  2012-03-26            323\n",
              "9         1975  2011-07-20            276"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3tH2uMSEq4zx"
      },
      "source": [
        "REMARKS\n",
        "\n",
        "- This is a convenient Jupyter trick. The results of the previous cell are always kept in a special variable called `_`. In this case it's a `%sql` magic resultset, which can be converted to a pandas DataFrame as shown. \n",
        "- The `_` trick only works once for each run of a `%%sql` cell. Can you figure out why? "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qVL7n_Rys_95"
      },
      "source": [
        "---\n",
        "## **Congratulations! You've made it to the end of Lesson 1.**\n",
        "\n",
        "There are just 11 more to go. For Quiz 1, focus on everything in this lesson but SQL. The purpose of this lesson was to provide necessary context *before* diving into SQL in Lesson 2. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "expHsirFAOWw"
      },
      "source": [
        "## **On your way out ... Be sure to save your work**.\n",
        "Save this notebook file to your `DATA6510` folder so you can find it next time. "
      ]
    }
  ]
}